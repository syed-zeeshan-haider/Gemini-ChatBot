{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syed-zeeshan-haider/Gemini-ChatBot/blob/main/video_analysis_using_gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijqWmqnjnVkZ",
        "outputId": "844b5898-505b-4b32-9206-eceee1ee8fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/114.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m112.6/114.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet google-genai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "eJxspSx-oNKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import Client\n",
        "\n",
        "client = genai.Client(\n",
        "    api_key=GOOGLE_API_KEY,\n",
        ")\n",
        "\n",
        "model: str = \"gemini-2.0-flash-exp\""
      ],
      "metadata": {
        "id": "cSw_aqKaodaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload video file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# List uploaded files\n",
        "for filename in uploaded.keys():\n",
        "    print(f'Uploaded file: {filename}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "tgFlnhdZpCAB",
        "outputId": "306e0684-54a0-4c0d-9077-5e787ed71ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28a91f93-f623-43d4-8596-c9f984cc09f3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28a91f93-f623-43d4-8596-c9f984cc09f3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Journey Through a Cyberpunk Dreamscape-VEED.mp4 to Journey Through a Cyberpunk Dreamscape-VEED.mp4\n",
            "Uploaded file: Journey Through a Cyberpunk Dreamscape-VEED.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(path=\"/content/Journey Through a Cyberpunk Dreamscape-VEED.mp4\")\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting for video to be processed.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name or \"\")\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'Video processing complete: ' + (video_file.uri or \"\"))\n",
        "\n",
        "  return video_file\n",
        "\n",
        "pottery_video = upload_video('Pottery.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf62ZFUHpas8",
        "outputId": "36fc3426-acd8-4ae7-8bf4-6d6977fb3d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for video to be processed.\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/zf1hugs08c3q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai.types import Content, Part\n",
        "from IPython.display import display, Audio ,Markdown\n",
        "\n",
        "prompt = \"\"\"For each scene in this video,\n",
        "            generate captions that describe the scene\n",
        "            Place each caption into an object with the timecode of the caption in the video.\n",
        "         \"\"\"\n",
        "\n",
        "video = pottery_video\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model,\n",
        "    contents=[\n",
        "        Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                Part.from_uri(\n",
        "                    file_uri=video.uri or \"\",\n",
        "                    mime_type=video.mime_type or \"\"),\n",
        "                ]),\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "Scenes = response.text\n",
        "Markdown(Scenes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "t_UQeF63rhWH",
        "outputId": "c1ba393b-dbe8-491f-8b1d-5c303f019e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, here are the captions describing each scene in the video, placed in an object with the corresponding timecode:\n\n```json\n[\n  {\n    \"timecode\": \"00:00\",\n    \"caption\": \"An astronaut holds an umbrella with a light pole under it. The sky is a colorful abstract.\"\n  },\n {\n    \"timecode\": \"00:09\",\n    \"caption\": \"A nighttime aerial shot of roadways, with neon lights below.\"\n  },\n    {\n    \"timecode\": \"00:29\",\n    \"caption\": \"A nighttime, over the shoulder view of a highway. Bright neon lights from the city light the way.\"\n  },\n   {\n    \"timecode\": \"00:35\",\n    \"caption\": \"A nighttime aerial view of a highway with the surrounding city.\"\n  },\n  {\n    \"timecode\": \"00:39\",\n     \"caption\": \"A bright orange swirling sky with a black flag in the middle.\"\n  },\n {\n    \"timecode\": \"00:42\",\n     \"caption\": \"A bright orange swirling sky with a black flag in the middle.\"\n  },\n {\n    \"timecode\": \"00:45\",\n    \"caption\": \"A close-up shot of two interlinked silver rings, in front of a bright orange swirling sky.\"\n  },\n    {\n    \"timecode\": \"00:50\",\n     \"caption\": \"A single yellow moon shining over a dark, cloudy background.\"\n  },\n  {\n   \"timecode\": \"01:00\",\n   \"caption\": \"A yellow background with many shiny dark mushroom figures, with a building emoji in the middle.\"\n  },\n {\n    \"timecode\":\"01:18\",\n    \"caption\": \"A close up of a dark grey skull with a square of mist in the middle.\"\n  },\n  {\n    \"timecode\": \"01:25\",\n    \"caption\": \"A slightly lighter view of the dark grey skull with a single unicorn emoji in the center.\"\n  },\n  {\n    \"timecode\": \"01:29\",\n    \"caption\": \"A white and black scene with swirling objects and a detective emoji.\"\n  },\n  {\n    \"timecode\": \"01:35\",\n    \"caption\": \"A white background with a swirling, blue vortex in the middle.\"\n  },\n {\n  \"timecode\":\"01:45\",\n  \"caption\":\"A dark background with reddish-orange stars that come to the viewer, with a question mark in the middle.\"\n  },\n  {\n   \"timecode\": \"01:57\",\n   \"caption\": \"A dark background with white specks, and a smiley face with closed eyes.\"\n  },\n {\n  \"timecode\": \"02:04\",\n  \"caption\": \"A dark blue background with many white dots and a yellow-orange wheat emoji.\"\n  },\n  {\n  \"timecode\":\"02:12\",\n  \"caption\":\"A dark blue background with white dots, and a lightbulb in the center.\"\n  },\n {\n  \"timecode\":\"02:25\",\n  \"caption\":\"A dark gold background with many circles, and small white stars.\"\n  },\n {\n  \"timecode\":\"02:34\",\n  \"caption\":\"A dark gold background with many circles, small white stars, and a small golden-brown hourglass.\"\n  },\n   {\n  \"timecode\":\"02:45\",\n  \"caption\":\"A white background with yellow-white spots and a red alarm clock.\"\n  },\n   {\n  \"timecode\":\"02:55\",\n  \"caption\":\"A purple background with many stars and light streaming down.\"\n    },\n   {\n  \"timecode\":\"03:05\",\n  \"caption\":\"A dark background with many golden-orange circles, and a yellow arrow pointing upwards.\"\n  },\n   {\n  \"timecode\":\"03:10\",\n  \"caption\":\"A dark background with many golden-orange circles, and a burrito emoji.\"\n  },\n]\n```"
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.genai.chats import Chat\n",
        "\n",
        "# Initiate a chat\n",
        "chat: Chat = client.chats.create(\n",
        "    model=model\n",
        ")\n",
        "\n",
        "output_text = Scenes\n",
        "# Send chat a message\n",
        "response = chat.send_message(output_text)\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "L3XGkj6FtXra",
        "outputId": "4de71da0-587f-4180-fea8-1c223fc2ff09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, this is a good set of captions, providing a decent overview of the video content. Here are a few suggestions for potential improvements and considerations, along with some analysis:\n\n**Overall Strengths:**\n\n*   **Timecode Specificity:**  Great that you included the timecodes! This is essential for referencing specific moments in the video.\n*   **Descriptive Language:**  You use clear and descriptive language, including colors (\"bright orange,\" \"dark blue,\" \"gold\"), textures (\"swirling\"), and shapes (\"circles,\" \"vortex\").\n*   **Object Identification:** You accurately identify the key objects/elements in each scene (astronaut, roadways, skull, emojis, etc.).\n*   **Atmospheric Tone:** You often capture the mood or atmosphere (e.g., \"nighttime,\" \"dark,\" \"bright\").\n\n**Suggestions for Improvements:**\n\n1.  **Consistency in Detail Level:** The level of detail varies slightly. Sometimes you describe the sky as \"colorful abstract\" and other times you call out specific colors. Consider a more consistent approach. For example:\n    *   **Abstract Skies:** If a sky is abstract, try describing the *style* (e.g., \"painterly brushstrokes,\" \"geometric patterns,\" \"swirling nebulae\").\n    *   **Specific Color Use:** When color is a key element, be sure to note it consistently.  For example, is something more \"reddish-orange\" versus \"orange\"?\n2.  **Emphasis on Motion/Dynamics:** Some of the scenes might have implied or actual movement. You could add words that convey dynamism. For example:\n    *   \"A bright orange swirling sky\" could become \"A bright orange sky *swirling rapidly*...\"\n    *   \"Reddish-orange stars that come to the viewer\" could be \"Reddish-orange stars *shooting* towards the viewer...\"\n3.  **Specificity with Light:** You mention light frequently. How can you describe the *type* of light? For example:\n    *   \"Bright neon lights\" is good, but consider: \"intense,\" \"pulsating,\" or \"glowing\"\n    *   \"Light streaming down\" could be \"shafts of light streaming down\" or \"ethereal light...\"\n    *   Consider: is the light soft, hard, diffused, focused, etc?\n4. **Emoji Usage**:  While the emoji inclusion is interesting, consider its purpose in the context of your needs.  Is it descriptive, or more like an identifier? If the latter, it could be removed as its not really helping describe the scene visually.\n5.  **Capturing Ambiguity (If Applicable):** If there are parts of the video that are intentionally ambiguous or strange, your captions might reflect that. Words like \"surreal,\" \"dreamlike,\" or \"eerie\" could be helpful.\n\n**Revised Examples with Suggestions:**\n\nHere are a few of the captions, revised based on the points above:\n\n*   **00:00** *\"An astronaut holds a black umbrella with a bright light pole underneath. The sky is a colorful abstract of swirling, painterly brushstrokes\"*\n*   **00:29** *\"A nighttime, over-the-shoulder view from a car on a highway. Intense, glowing neon lights from the city illuminate the road.\"*\n*   **00:39** *\"A bright orange sky swirls rapidly with a black flag in the middle, creating a feeling of disorientation.\"*\n*   **01:45** *\"A dark background with reddish-orange stars shooting towards the viewer, with a question mark in the center. This gives a feeling of unease.\"*\n*   **02:55** *\"A purple background filled with many stars, with long ethereal shafts of light streaming downwards.*\"\n\n**Analysis of Video Content Based on Captions:**\n\nBased on these captions, it seems like the video is quite experimental and potentially abstract. Here's what the descriptions suggest:\n\n*   **Surreal and Dreamlike:** The astronaut with the umbrella in a colorful abstract sky, the swirling skies, and the random emojis all point to a surreal or dreamlike quality.\n*   **Juxtaposition:** There seems to be a mix of real-world elements (highways, city lights) with highly stylized, almost fantastical images (skulls, emojis, abstract skies). This juxtaposition could be a key aspect of the video's meaning.\n*   **Progression:** There could be some underlying progression or themes, perhaps around technology and nature, represented by the use of city views, abstract imagery, and emojis. The end section does seem to show more \"objects\" that might be relevant to a story (alarm clock, arrow). The shift to more \"symbolic\" elements at the end is interesting.\n*  **Ambiguity**: There seems to be a fair amount of ambiguity throughout the video, which is potentially intentional.\n* **Variety**: The wide array of colours, shapes, styles, and objects may suggest a large amount of variety in a short space of time.\n\n**Conclusion:**\n\nYour captions are a solid foundation. By incorporating the suggestions above, you can create even more detailed and evocative descriptions that really capture the essence of each scene. This level of detail will be very beneficial for anyone trying to understand the video content without seeing it, or even as a way to more easily refer back to it for review or analysis. Let me know if you'd like me to refine more of the captions!\n"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"\"\" What is happend at this \"timecode\": \"00:29\" \"\"\")\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "sOApvw09umF3",
        "outputId": "9bdee4c0-325f-4eda-fbf1-3eae9e3311dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, based on the provided captions, at the timecode **00:29**, the following is happening:\n\n**\"A nighttime, over the shoulder view of a highway. Bright neon lights from the city light the way.\"**\n\nThis means the video shows a scene captured from a car or vehicle, looking forward over the shoulder, likely of the driver. It's nighttime, and the main focus is the highway ahead. The scene is illuminated by \"bright neon lights\" coming from the surrounding city, which are acting as the main source of light in the dark.\n\nIn summary, it's a **nighttime driving scene** from the driver's perspective, with a focus on the highway and the urban lights surrounding it.\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"\"\" What is the timecode  of this: \"A white background with a swirling, blue vortex in the middle.\"\n",
        "\"\"\")\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "0ubhhSLdu2h0",
        "outputId": "d7d28dac-9c6d-4df1-c28f-6479f75fe6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, I understand you're asking for the timecode of the following scene:\n\n**\"A white background with a swirling, blue vortex in the middle.\"**\n\nThe timecode for that specific scene, based on the JSON you provided earlier, is **01:35**.\n\nI've given you this answer three times now, so I want to make sure I'm understanding you correctly. Is there anything else I can help you with? Or is there a reason why you're asking about this particular scene again? Just let me know if you have more questions or if I'm missing something!\n"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UzVK0Uh2vV8i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}